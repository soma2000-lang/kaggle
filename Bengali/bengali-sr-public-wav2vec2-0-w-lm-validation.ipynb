{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":52324,"databundleVersionId":6229904,"sourceType":"competition"},{"sourceId":140325995,"sourceType":"kernelVersion"}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## About\n\nThis notebook calculates valid WER score for models used in the submission: [Bengali-SR: Public Wav2vec2.0 w/ LM Baseline](https://www.kaggle.com/code/ttahara/bengali-sr-public-wav2vec2-0-w-lm-baseline). ","metadata":{}},{"cell_type":"markdown","source":"## Import","metadata":{}},{"cell_type":"code","source":"!pip install jiwer\n!pip install bnunicodenormalizer\n!pip install pyctcdecode\n!pip install kenlm","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-23T19:06:41.886733Z","iopub.execute_input":"2024-07-23T19:06:41.887228Z","iopub.status.idle":"2024-07-23T19:08:27.110530Z","shell.execute_reply.started":"2024-07-23T19:06:41.887202Z","shell.execute_reply":"2024-07-23T19:08:27.109367Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting jiwer\n  Downloading jiwer-3.0.4-py3-none-any.whl (21 kB)\nRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (8.1.3)\nRequirement already satisfied: rapidfuzz<4,>=3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (3.1.1)\nInstalling collected packages: jiwer\nSuccessfully installed jiwer-3.0.4\nCollecting bnunicodenormalizer\n  Downloading bnunicodenormalizer-0.1.7-py3-none-any.whl (23 kB)\nInstalling collected packages: bnunicodenormalizer\nSuccessfully installed bnunicodenormalizer-0.1.7\nCollecting pyctcdecode\n  Downloading pyctcdecode-0.5.0-py2.py3-none-any.whl (39 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from pyctcdecode) (1.23.5)\nCollecting pygtrie<3.0,>=2.1 (from pyctcdecode)\n  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\nCollecting hypothesis<7,>=6.14 (from pyctcdecode)\n  Downloading hypothesis-6.108.4-py3-none-any.whl (465 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.2/465.2 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (23.1.0)\nRequirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (2.4.0)\nRequirement already satisfied: exceptiongroup>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (1.1.1)\nInstalling collected packages: pygtrie, hypothesis, pyctcdecode\nSuccessfully installed hypothesis-6.108.4 pyctcdecode-0.5.0 pygtrie-2.5.0\nCollecting kenlm\n  Downloading kenlm-0.2.0.tar.gz (427 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.4/427.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: kenlm\n  Building wheel for kenlm (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for kenlm: filename=kenlm-0.2.0-cp310-cp310-linux_x86_64.whl size=587010 sha256=08ebe4fab0e0912f48397c530ec572c6e3c4d0d15dc79e28d52446c117dcc6eb\n  Stored in directory: /root/.cache/pip/wheels/fd/80/e0/18f4148e863fb137bd87e21ee2bf423b81b3ed6989dab95135\nSuccessfully built kenlm\nInstalling collected packages: kenlm\nSuccessfully installed kenlm-0.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install numpy==1.22","metadata":{"execution":{"iopub.status.busy":"2024-07-23T19:11:54.195387Z","iopub.execute_input":"2024-07-23T19:11:54.196250Z","iopub.status.idle":"2024-07-23T19:12:11.730642Z","shell.execute_reply.started":"2024-07-23T19:11:54.196213Z","shell.execute_reply":"2024-07-23T19:12:11.729602Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting numpy==1.22\n  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Uninstalling numpy-1.23.5:\n      Successfully uninstalled numpy-1.23.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.6.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nchex 0.1.81 requires numpy>=1.25.0, but you have numpy 1.22.0 which is incompatible.\ncudf 23.6.1 requires protobuf<4.22,>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.6.0 requires dask==2023.3.2, but you have dask 2023.7.0 which is incompatible.\ndask-cuda 23.6.0 requires dask==2023.3.2, but you have dask 2023.7.0 which is incompatible.\ndask-cudf 23.6.1 requires dask==2023.3.2, but you have dask 2023.7.0 which is incompatible.\nlibrosa 0.10.0.post2 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.22.0 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.1 which is incompatible.\nraft-dask 23.6.2 requires dask==2023.3.2, but you have dask 2023.7.0 which is incompatible.\nydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.22.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import typing as tp\nfrom pathlib import Path\nfrom functools import partial\nfrom dataclasses import dataclass, field\n\nimport pandas as pd\nimport pyctcdecode\nimport numpy as np\nfrom tqdm.notebook import tqdm\n\nimport librosa\n\nimport jiwer\nimport pyctcdecode\nimport kenlm\nimport torch\nfrom transformers import Wav2Vec2Processor, Wav2Vec2ProcessorWithLM, Wav2Vec2ForCTC\nfrom bnunicodenormalizer import Normalizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-23T19:12:35.587907Z","iopub.execute_input":"2024-07-23T19:12:35.588329Z","iopub.status.idle":"2024-07-23T19:12:35.594444Z","shell.execute_reply.started":"2024-07-23T19:12:35.588293Z","shell.execute_reply":"2024-07-23T19:12:35.593104Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"ROOT = Path.cwd().parent\nINPUT = ROOT / \"input\"\nDATA = INPUT / \"bengaliai-speech\"\nTRAIN = DATA / \"train_mp3s\"\nTEST = DATA / \"test_mp3s\"\n\nSAMPLING_RATE = 16_000\nMODEL_PATH = INPUT / \"bengali-sr-download-public-trained-models/indicwav2vec_v1_bengali/\"\nLM_PATH = INPUT / \"bengali-sr-download-public-trained-models/wav2vec2-xls-r-300m-bengali/language_model/\"","metadata":{"execution":{"iopub.status.busy":"2024-07-23T19:12:38.616718Z","iopub.execute_input":"2024-07-23T19:12:38.617472Z","iopub.status.idle":"2024-07-23T19:12:38.622315Z","shell.execute_reply.started":"2024-07-23T19:12:38.617441Z","shell.execute_reply":"2024-07-23T19:12:38.621533Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### load model, processor, decoder","metadata":{}},{"cell_type":"code","source":"model = Wav2Vec2ForCTC.from_pretrained(MODEL_PATH)\nprocessor = Wav2Vec2Processor.from_pretrained(MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T19:13:02.284557Z","iopub.execute_input":"2024-07-23T19:13:02.284920Z","iopub.status.idle":"2024-07-23T19:13:05.895900Z","shell.execute_reply.started":"2024-07-23T19:13:02.284876Z","shell.execute_reply":"2024-07-23T19:13:05.894912Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"vocab_dict = processor.tokenizer.get_vocab()\nsorted_vocab_dict = {k: v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n\ndecoder = pyctcdecode.build_ctcdecoder(\n    list(sorted_vocab_dict.keys()),\n    str(LM_PATH / \"5gram.bin\"),\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T19:13:54.733402Z","iopub.execute_input":"2024-07-23T19:13:54.733690Z","iopub.status.idle":"2024-07-23T19:13:54.878525Z","shell.execute_reply.started":"2024-07-23T19:13:54.733665Z","shell.execute_reply":"2024-07-23T19:13:54.877783Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"processor_with_lm = Wav2Vec2ProcessorWithLM(\n    feature_extractor=processor.feature_extractor,\n    tokenizer=processor.tokenizer,\n    decoder=decoder\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T19:14:06.244635Z","iopub.execute_input":"2024-07-23T19:14:06.244986Z","iopub.status.idle":"2024-07-23T19:14:06.249582Z","shell.execute_reply.started":"2024-07-23T19:14:06.244959Z","shell.execute_reply":"2024-07-23T19:14:06.248621Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"## prepare dataloader","metadata":{}},{"cell_type":"code","source":"class BengaliSRTestDataset(torch.utils.data.Dataset):\n    \n    def __init__(\n        self,\n        audio_paths: list[str],\n        sampling_rate: int\n    ):\n        self.audio_paths = audio_paths\n        self.sampling_rate = sampling_rate\n        \n    def __len__(self,):\n        return len(self.audio_paths)\n    \n    def __getitem__(self, index: int):\n        audio_path = self.audio_paths[index]\n        sr = self.sampling_rate\n        w = librosa.load(audio_path, sr=sr, mono=False)[0]\n        \n        return w","metadata":{"execution":{"iopub.status.busy":"2024-07-23T19:14:39.868480Z","iopub.execute_input":"2024-07-23T19:14:39.868782Z","iopub.status.idle":"2024-07-23T19:14:39.874874Z","shell.execute_reply.started":"2024-07-23T19:14:39.868758Z","shell.execute_reply":"2024-07-23T19:14:39.874010Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"valid = pd.read_csv(DATA / \"train.csv\", dtype={\"id\": str}).query(\"split == 'valid'\").reset_index(drop=True)\nprint(valid.head())","metadata":{"execution":{"iopub.status.busy":"2024-07-23T19:14:46.370725Z","iopub.execute_input":"2024-07-23T19:14:46.371028Z","iopub.status.idle":"2024-07-23T19:14:49.796115Z","shell.execute_reply.started":"2024-07-23T19:14:46.371002Z","shell.execute_reply":"2024-07-23T19:14:49.795132Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"             id                                           sentence  split\n0  0000e711c2b1  তিনি এবং তাঁর মা তাদের পৈতৃক বাড়িতে থেকে প্রত...  valid\n1  00036c2a2d9d  কৃত্তিবাস রামায়ণ-বহির্ভূত অনেক গল্প এই অনুবাদ...  valid\n2  00065e317123  তিনি তার সুশৃঙ্খল সামরিক বাহিনী এবং সুগঠিত শাস...  valid\n3  00065f40df52  তিনি বিজয়নগর সাম্রাজ্যের বিরুদ্ধে এবং বিজাপুর...  valid\n4  0009b022c8ea                        এটি মূলত একটি মরুময় অঞ্চল।  valid\n","output_type":"stream"}]},{"cell_type":"code","source":"valid_audio_paths = [str(TRAIN / f\"{aid}.mp3\") for aid in valid[\"id\"].values]","metadata":{"execution":{"iopub.status.busy":"2024-07-23T19:17:40.697625Z","iopub.execute_input":"2024-07-23T19:17:40.697942Z","iopub.status.idle":"2024-07-23T19:17:40.936583Z","shell.execute_reply.started":"2024-07-23T19:17:40.697908Z","shell.execute_reply":"2024-07-23T19:17:40.935855Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"valid_dataset = BengaliSRTestDataset(\n    valid_audio_paths, SAMPLING_RATE\n)\n\ncollate_func = partial(\n    processor_with_lm.feature_extractor,\n    return_tensors=\"pt\", sampling_rate=SAMPLING_RATE,\n    padding=True,\n)\n\nvalid_loader = torch.utils.data.DataLoader(\n    valid_dataset, batch_size=8, shuffle=False,\n    num_workers=2, collate_fn=collate_func, drop_last=False,\n    pin_memory=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T19:17:44.493045Z","iopub.execute_input":"2024-07-23T19:17:44.493384Z","iopub.status.idle":"2024-07-23T19:17:44.498941Z","shell.execute_reply.started":"2024-07-23T19:17:44.493357Z","shell.execute_reply":"2024-07-23T19:17:44.498007Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"if not torch.cuda.is_available():\n    device = torch.device(\"cpu\")\nelse:\n    device = torch.device(\"cuda\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T19:17:46.644986Z","iopub.execute_input":"2024-07-23T19:17:46.645352Z","iopub.status.idle":"2024-07-23T19:17:46.650441Z","shell.execute_reply.started":"2024-07-23T19:17:46.645323Z","shell.execute_reply":"2024-07-23T19:17:46.649495Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"model = model.to(device)\nmodel = model.eval()\nmodel = model.half()","metadata":{"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"bnorm = Normalizer()\n\ndef postprocess(sentence):\n    period_set = set([\".\", \"?\", \"!\", \"।\"])\n    _words = [bnorm(word)['normalized']  for word in sentence.split()]\n    sentence = \" \".join([word for word in _words if word is not None])\n    try:\n        if sentence[-1] not in period_set:\n            sentence+=\"।\"\n    except:\n        # print(sentence)\n        sentence = \"।\"\n    return sentence","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_sentence_list = []\n\nwith torch.no_grad():\n    for batch in tqdm(valid_loader):\n        x = batch[\"input_values\"]\n        x = x.to(device, non_blocking=True)\n        with torch.cuda.amp.autocast(True):\n            y = model(x).logits\n        y = y.detach().cpu().numpy()\n        \n        for l in y:  \n            sentence = processor_with_lm.decode(l, beam_width=512).text\n            pred_sentence_list.append(sentence)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check Valid WER score","metadata":{}},{"cell_type":"code","source":"pp_pred_sentence_list = [\n    postprocess(s) for s in tqdm(pred_sentence_list)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid[\"pred_sentence\"] = pp_pred_sentence_list\nvalid[\"wer\"] = [\n    jiwer.wer(s, p_s)\n    for s, p_s in tqdm(valid[[\"sentence\", \"pred_sentence\"]].values)\n]\n\nprint(valid.head())","metadata":{"execution":{"iopub.status.busy":"2023-08-19T02:58:22.727219Z","iopub.status.idle":"2023-08-19T02:58:22.72826Z","shell.execute_reply.started":"2023-08-19T02:58:22.728004Z","shell.execute_reply":"2023-08-19T02:58:22.728034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(valid[\"wer\"].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EOF","metadata":{}}]}